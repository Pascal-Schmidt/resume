section,in_resume,title,loc,institution,start,end,description_1,description_2,description_3,description_4,description_5
education,TRUE,"B.S., Statistics, (Minor Economics)",Simon Fraser University,"Burnaby, BC",2014,2019,.,,,,
industry_positions,TRUE,Data Science Co-op,Statistics Canada,"Ottawa, ON", May 2019, August 2019,Developed functions for cleaning multiple data sets based on key criteria identified by our team and built the data set ready for analysis by using sql join commands.,Created graphs and tables in ggplot2 for a better understanding of why people's addresses on administrative data matches that on census data.,Modelled a logistic regression and interpreted the odds ratios for a better understanding of which predictors explain the reason of consistent addresses between admin data and census data. Project code can be found on my [github](https://github.com/Pascal-Schmidt/statistics-canada).,,
projects,TRUE,[A Data-Driven Approach to Evaluating the Vancouver Housing Market](https://shiny.pascal-schmidt-ds.com/vancouver-housing-analysis/),"<strong>Tools Used:</strong> Shiny, Bootstrap, CSS, Docker, Docker Compose, MongoDB, AWS, shinyjs, leaflet, tidyverse, tidymodels, selenium, random forest ",, present, January 2018,"Scraped multiple real estate websites for property prices and features and created a cleaned, standardized, and tidy data set for analysis.",Fitted a random forest model with the `tidymodels` package that predicted home and rental prices and calculated price to rent ratios to inform Vancouverites about the best properties.,Improved the random forest model (decreased the MAE by 20%) by augmenting the data set with new feature engineered variables by leveraging the Google Maps API.,Created an interactive web application that serves as an exploratory tool and lets users use the machine learning model to make predictions about any desired property in Vancouver.,Deployed the application with the help of Docker on AWS and made it available to the public.
projects,TRUE,[Twitter Exploration Tool](https://shiny.pascal-schmidt-ds.com/keywords),"<strong>Tools Used:</strong> Shiny, CSS, Bootstrap, DataTable, leaflet, plotly, shinyjs, rtweet  ",,,,Developed a web application that lets users explore the usage of words on Twitter for specified cities around the world.,"Implemented a network graph that visualizes bigrams from Tweets and created word clouds for handles, hashtags, and mentions to explore how people talk about topics on Twitter.",,,
projects,TRUE,[Matrix Completion of Weather Data](https://thatdatatho.com/portfolio/kaggle-matrix-completion-of-weather-matrix/),"<strong>Tools Used:</strong> R, Rcpp, Python, pandas, numpy ",,,,Won the in-class Kaggle competition by exploring NA values in the data set and predicting the missing values with a combination of linear interpolation and linear regression.,Implemented a function in C++ that identified large gaps of missing values between observations and helped me choose between interpolation and regression. ,Decreased the run time of my notebook by 80% by re-writing some code blocks in C++. ,,
projects,TRUE,[Personal Blog](http://thatdatatho.com/),<strong>Tools Used:</strong> Passion to learn and teach data science and programming,,,,"Published blog posts about programming in R and Python, using and exploring specific libraries, developing web applications with shiny, building predictive models, and statistics and data science concepts. ",,Learned and internalized data science and programming principles better by teaching readers about concepts I am learning about. ,,
