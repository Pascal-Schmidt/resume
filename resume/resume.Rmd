---
title: Pascal Schmidt's Resume"
author: Pascal Schmidt
date: "`r Sys.Date()`"
linkcolor: blue
output:
  pagedown::html_resume:
    css: ['css/custom_resume.css', 'css/styles.css', 'resume']
    # set it to true for a self-contained HTML page but it'll take longer to render
    self_contained: true
---

```{r, include=FALSE}
knitr::opts_chunk$set(
  results='asis', 
  echo = FALSE
)
library(tidyverse)
library(glue)

# Set this to true to have links turned into footnotes at the end of the document
PDF_EXPORT <- FALSE

# Holds all the links that were inserted for placement at the end
links <- c()

source('parsing_functions.R')


# First let's get the data, filtering to only the items tagged as
# Resume items
position_data <- read_csv('positions.csv') %>% 
  filter(in_resume) %>% 
  mutate(
    # Build some custom sections by collapsing others
    section = case_when(
      section %in% c('research_positions', 'industry_positions') ~ 'positions', 
      section %in% c('data_science_writings', 'by_me_press') ~ 'writings',
      TRUE ~ section
    )
  ) 

```


Aside
================================================================================

Contact {#contact}
--------------------------------------------------------------------------------

- <i class="fa fa-envelope"></i> pascal.sfu@gmail.com
- <i class="fab fa-linkedin-in"></i> [Pascal-Schmidt](https://www.linkedin.com/in/pascal-data-science/)
- <i class="fa fa-github"></i> [Pascal-Schmidt](http://github.com/Pascal-Schmidt)
- <i class="fa fa-link"></i> [thatdatatho](http://thatdatatho.com)



Skills {#skills}
--------------------------------------------------------------------------------

- R/RStudio
- Shiny
- Markdown
- Python
- C++
- SQL 
- Power BI
- Docker
- AWS
- Version Control
- Statistical Analysis


Commonly Used Libraries
------------------------------------------------

- `tidyverse` 
- `tidymodels` 
- `shiny` + `shinyjs`
- `flexdashboard`
- `Rcpp`
- `pandas`
- `NumPy`
- `scikit-learn`

Research {#Research}
--------------------------------------------------------------------------------

- [Molecular subtype not immune response drives outcomes in endometrial carcinoma](https://clincancerres.aacrjournals.org/content/25/8/2537)


Main
================================================================================

Pascal Schmidt {#title}
--------------------------------------------------------------------------------

```{r}
intro_text <- "I am currently working as a data analyst, building dashboards, testing hypothesis, and doing all different kinds of data analysis. The main tools I use are R, Shiny, Python, and SQL. When I am not working my day job, I am blogging at [thatdatatho.com](http://thatdatatho.com) and building web applications on my [personal website](https://shiny.pascal-schmidt-ds.com/) about data that interests me."

cat(sanitize_links(intro_text))
```



Education {data-icon=graduation-cap data-concise=true}
--------------------------------------------------------------------------------

### B.S., Statistics, (Minor Economics)

Simon Fraser University, in-major GPA: 3.55

Burnaby, BC

2014 - 2019		


Work Experience {data-icon=suitcase}
--------------------------------------------------------------------------------

### Data Analyst

LBC Studios

Vancouver, BC

November 2020 - Current

- Investigated returns on bundle purchases by testing multiple hypotheses and recommended different price points that led to increased revenue for the analyzed bundles. 
- Provided dashboards and reports to the marketing team to better understand marketing campaigns and revenue flow.


### Data Analyst

SAM	

Edmonton, AB	

June 2020 - November 2020	

-	Deployed and dockerized a web application on AWS with R Shiny that analyzed real-time Twitter data, which led to increased productivity of employees who used the application for research purposes. 
-	Queried, cleaned, and visualized data with the help of `pandas`, `NumPy`, and Python plotting libraries to update teams about machine learning model performances.
-	Developed automated interactive dashboards with `plotly` and `flexdashboard` to inform teams about the internal data usage and to improve the client experience by sending out quality information. 



### Data Analyst, co-op	

Statistics Canada	

Ottawa, ON	

May 2019 - August 2019	

-	Developed R scripts for cleaning multiple data sets and used SQL joins to build a usable data set for analysis. 
-	Built an R markdown report with tables and graphs for a better understanding of why peopleâ€™s addresses on administrative data match that on census data.
-	Created data visualization plots in Power BI to supplement the R markdown report.
-	Presented data and conclusions to my team, which used the results to gain actionable insights into the Census Program Transformation Project and improved the population coverage for admin data. 
 
	

### Data Science Trainee	

BC Cancer Agency	

Vancouver, BC	 

May 2018 - December 2018	

-	Designed reports and conducted an explanatory data analysis, which led to a successful publication, by visualizing the key characteristics of patients with endometrial cancer.
-	Produced interactive dashboards to communicate data to physicians who used my work for presentations.
-	Independently researched and applied previously unknown statistical libraries for improved data representation.  
-	Composed a bi-annual report by cleaning, reshaping, and joining multiple unstructured data sources, working extensively with R tidyverse packages such as `dplyr`, `ggplot`, `purrr`, `tidyr`, and `stringr`.
-	Implemented a meta-analysis of individual patient data and a cox-regression model to determine if endometrial cancer patients need additional treatment plans and to improve their quality of life. 




<i class="fas fa-project-diagram"></i> Projects
--------------------------------------------------------------------------------

```{r}
print_section <- function(position_data, section_id){
  position_data %>% 
    filter(section == section_id) %>% 
    arrange(desc(end)) %>% 
    mutate(id = 1:n()) %>% 
    pivot_longer(
      starts_with('description'),
      names_to = 'description_num',
      values_to = 'description',
      values_drop_na = TRUE
    ) %>% 
    group_by(id) %>% 
    mutate(
      descriptions = list(description)
    ) %>% 
    ungroup() %>% 
    filter(description_num == 'description_1') %>% 
    mutate(
      timeline = ifelse(
        is.na(start) | start == end,
        end,
        glue('{end} - {start}')
      ),
      description_bullets = map_chr(descriptions, ~paste('-', ., collapse = '\n')),
    ) %>% 
    strip_links_from_cols(c('title', 'description_bullets')) %>% 
    mutate_all(~ifelse(is.na(.), 'N/A', .)) %>% 
    glue_data(
      "### {title}",
      "\n\n",
      "{description_bullets}",
      "\n\n\n",
    )
}

source('parsing_functions.R')
position_data %>% print_section('projects')
```

<i class="fas fa-book"></i> Professional Development 
--------------------------------------------------------------------------------

### Tutoring

N/A

N/A

- Tutored students in programming and statistics classes to help students achieve their learning and grade goals and to build a strong foundation of these concepts for myself.

### Kaggle Meet Ups

N/A

N/A

- Visited the Kaggle meet-up group and learned about competitions, algorithm implementation, and data science concepts.

### Online Classes

N/A

N/A

- Completed online classes on platforms such as Business Science, Coursera, and Data360 to learn new technologies and expand my horizon as a data scientist.

### #TidyTuesday

N/A

N/A

- Participated in weekly challenges that consisted of a data set, posted by R Studio for the R community, to analyze and then share the findings and analysis with the community on Twitter.

